\documentclass[a4paper]{article}
\usepackage{import}
\input{../../setup.sty}
% Set custom margins
\onehalfspacing

\geometry{a4paper, margin=1in}
\geometry{letterpaper, left=1.5in, right=1in, top=1in, bottom=1in}

\title{Analisi II}
\author{Università di Verona\\Imbriani Paolo - VR500437\\Professor Zivcovich Franco}

% Make section titles bigger
\titleformat{\section}[hang]{\huge\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}[hang]{\Large\normalfont\itshape}{\thesubsection}{1em}{}

\usepackage[italian]{babel}

\addto\captionsitalian{% Replace "english" with the language you use
  \renewcommand{\contentsname}%
    {Indice}%
}

\numberwithin{equation}{subsection}

\begin{document}

\begin{figure}
    \centering
    \includegraphics[width=0.3\textwidth]{../UniversityofVerona.png}
\end{figure}

\maketitle 

\pagebreak

\tableofcontents

\pagebreak

\section{Equazioni differenziali}

\subsection{Modelli differenziali}

La fisica, per descrivere dei fenomeni fisici usano la matematica e in particolare le equazioni differenziali. Infatti, si denota $x(t)$ lo spostamento nel tempo.
Con la derivata prima $x'(t)$ si denota la velocità della particella in quell'istante e con la derivata seconda $x''(t)$ l'accelerazione.
Quindi quando andiamo a tradurre
matematicamente le leggi che governano modelli naturali può essere naturale dover lavorare
con equazioni che coinvolgono una funzione incognita e qualcuna delle sue derivate.

\ex{}{La seconda legge del moto di Newton $F = ma$, che stabilisce la posizione
$x(t)$ al tempo $t$ di un corpo di massa m costante, soggetto a una forza $F(t)$, deve soddisfare
l'equazione differenziale:
\[m\frac{d^2x}{dt^2} = F(t) \; \; \text{equazione del moto}\]
}
\noindent
Quindi le equazioni differenziali nascono per descrivere fenomeni fisici e naturali. 
Possono essere classificate in modi diversi. Abbiamo infatti:
\begin{enumerate}
    \item \textit{Equazioni differenziali ordinarie} (ODE) se vengono coinvolte solo le derivate rispetto ad una sola variabile oppure \textit{equazioni differenziali parziali} (PDE) se vengono coinvolte derivate parziali
     dell'incognita rispetto a più variabili.
     \ex{}{L'equazione: \[\frac{\partial^2 u}{\partial t^2}=c^2 \frac{\partial^2u}{\partial x^2}\]
     rappresenta l'equazione delle onde che modellizza lo spostamento trasversale $u(x, t)$ nel
punto $x$ al tempo $t$ di una corda tesa che può vibrare.
     }
    \item Classificazione in base all'ordine: l'ordine di una ED è l'ordine massimo di derivazione che
    compare nell'equazione.
\ex{}{L'equazione: \[\frac{dy^2}{dt^2} + ty^3 - \cos{y} = \sin{t} \; \; \; \; \; \; \text{è di ordine 2}\]
 \[\frac{d^3y}{dt^3} - 2t\left(\frac{dy}{dt}\right)^2  = y \frac{dy^2}{dt^2} - e^t\; \; \; \; \; \; \text{è di ordine 3}\]
}
Possiamo dunque formalizzare i concetti finora introdotti attraverso la seguente definizione:
\end{enumerate}
\dfn{Equazione differenziale}{
Si dice \textbf{equazione differenziale} di ordine $n$ un'equazione del tipo
\begin{equation}
    F(t,y',y'', \dots , y^{(n)}) = 0   
\end{equation}
dove $y(t)$ è la funzione incognita e $F$ è una funzione assegnata delle $n + 2$ variabili $t, y, y'
, \dots , y(n)$ a valori reali.
\\
Si dice \textbf{ordine} di un'equazione differenziale il massimo ordine di derivazione che compare nell'equazione.\\
Si dice \textbf{soluzione (o curva integrale)} di (1.1.1) nell'intervallo $I \subset \mathbb{R}$ una funzione $\varphi$, definita almeno in $I$ e a valori reali per cui risulti:
\begin{equation*}
F(t, \varphi'(t), \varphi''(t), \dots , \varphi^{(n)}(t)) = 0 \; \; \; \; \; \; \forall t \in I
\end{equation*}
Infine si dice integrale generale dell'equazione (1.1.1) una formula che rappresenti la famiglia
di tutte le soluzioni dell'equazione (1.1.1), eventualmente al variare di uno o più parametri in essa
contenuti.
}
\ex{}{
Consideriamo una popolazione di individui, animali o vegetali che siano,
e sia $N(t)$ il numero degli individui. Osserviamo che N è funzione di del tempo $t$, assume solo
valori interi ed è a priori una funzione discontinua di t; tuttavia può essere approssimata da
una funzione continua e derivabile purché il numero degli individui sia abbastanza grande.
Supponiamo che la popolazione sia isolata e che la proporzione degli individui in età riproduttiva e la fecondità siano costanti.
Se escludiamo i casi di morte, immigrazione, emigrazione, allora il tasso di accrescimento coincide con quello di natalità 
e se indichiamo con $\lambda$ il tasso specifico di natalità (i.e. il numero
di nati per unità di tempo) l'equazione che descrive il modello diventa:
\[\frac{dN}{dt} = \lambda N(t)\]
Questo processo risulta realistico solo in popolazioni che crescono in situazioni ideali e sono
assenti tutti i fattori che ne impediscono la crescita.
}
La stessa equazione compare anche in altri modelli relativi a sistemi fisiologici ed ecologici.
\ex{}{Studiamo ora il modello di crescita (dovuto a Malthus, 1978) relativo
all'evoluzione di una popolazione isolata in presenza di risorse limitate ed in assenza di predatori
o antagonisti all'utilizzo delle risorse. In questo caso l'equazione che si ottiene è la seguente:
\begin{equation*}
    \frac{dN}{dt} = \lambda N(t) - \mu N(t)
\end{equation*}
dove come prima $\lambda$ è il tasso di natalità mentre $\mu$ è il tasso di mortalità (cioè rispettivamente
il numero di nati e morti nell'unità di tempo). Il numero $\varepsilon = \lambda - \mu$ è detto \textbf{potenziale
biologico.}
}
\noindent
Ci chiediamo ora come possiamo trovare una soluzione del problema studiato nell'Esempio
1.5. Supponiamo per il momento che sia $N \neq 0$. Allora:
\begin{equation*}
N = \varepsilon N = \frac{N}{N} = \varepsilon \Longrightarrow \frac{d}{dt} (\log{|N|}) = \varepsilon,
\end{equation*}
da cui otteniamo:
\begin{equation*}
\log{|N(t)|} = \varepsilon t + c_1 \Longrightarrow |N(t)| = e^{c_1}e^{\varepsilon t} =: k^2 e^{\varepsilon t}
\end{equation*}
dove abbiamo posto $e^{c_1} =: k^2 > 0$ costante positiva e arbitraria. A questo punto allora:
\[N(t) = \pm k^2e^{\varepsilon t}\]
Quindi possiamo dire sicuramente che:
\[N(t) = Ce^{\varepsilon t} \; \; \; C \in \mathbb{R} \backslash \{0\} \]
Tutto questo vale se $N \neq 0$; ma è banale verificare che anche $N = 0$ soddisfa l'equazione di
partenza, quindi possiamo dire che l'integrale generale è:
\[N(t) = Ce^{\varepsilon t} = Ce^{(\lambda - \mu)t} \; \; \; C \in \mathbb{R}\]
In particolare dall'ultima riga leggiamo che:
\begin{enumerate}
    \item Se $\lambda > \mu$ allora $N(t)$ è una funzione che cresce in maniera esponenziale.
    \item Se $\lambda < \mu$ allora $N(t)$ è una funzione che decresce fino ad estinguersi. 
    \item Se $\lambda = \mu$ allora $N(t)$ è una funzione stabile nel tempo.
\end{enumerate}
Osserviamo in particolare che non abbiamo trovato solo una soluzione, ma infinite soluzioni,
dipendenti da una costante arbitraria.

\subsection{Equazioni differenziali di primo ordine}

\subsubsection{Generalità}

Le equazioni differenziali di primo ordine sono le più semplici da trattare e sono di fondamentale importanza in quanto sono alla base di molte applicazioni pratiche.
Esse sono della forma:
\begin{equation}
    F(t, y, y') = 0
\end{equation}
con $F$ funzione assegnata delle tre variabili $t, y, y'$ a valori reali.
\ex{}{
    La ricerca delle primitive di una funzione $f$ continua su un intervallo $I$
    equivale a risolvere l'equazione differenziale $y'(t) = f(t)$ che ammette infinite soluzioni del tipo
\begin{equation*}
    y(t) = \int f(t) \; dt + C \; \; \; \; \; \; C \in \mathbb{R}
\end{equation*}
}
\noindent
\textbf{Si dimostra} che l'insieme delle soluzioni di una EDO del primo ordine è costituito da una famiglia di funzioni dipendenti da un parametro 
$C: t \mapsto \varphi(t; c)$. Tale famiglia prende il nome di \textbf{integrale generale} dell'equazione differenziale.
La condizione supplementare $y(t_0) = y_0$ permette di selezionare una soluzione specifica.
\dfn{Problema di Cauchy}{
Il problema di risolvere il seguente sistema di equazioni:
\begin{equation}
\begin{cases}
    F(t, y, y') = 0 \\
    y(t_0) = y_0
\end{cases}
\end{equation}
prende il nome di \textbf{problema di Cauchy}.
}
\dfn{Forma Normale}{
Un'equazione differenziale ordinaria del primo ordine si dice in \textbf{forma normale} se è scritta nella forma:
\begin{equation}
    y'(t) = f(t, y)
\end{equation}
}
\noindent
Per equazioni di questo tipo si può assicurare, sotto larghe ipotesi, che il problema di Cauchy (1.2.2) ammette un'unica soluzione almeno 
localmente (cioè per valori di $t$ in un intorno di $t_0$).
\\
Le soluzioni dell'ED espresse dall'integrale generale potrebbero talvolta
essere definite su insiemi diversi a seconda del valore della costante o anche su insiemi più complicati
di un intervallo (es. $t \neq 0$). Tuttavia quando parleremo di soluzione del problema di Cauchy andremo
sempre a intendere una funzione che:
\begin{itemize}
    \item[a)] è definita su un intervallo $I$ contenente $t_0$ in cui è assegnata la condizione iniziale.
    \item[b)] è derivabile in ogni punto di $I$ e soddisfa l'equazione in ogni punto di $I$. 
\end{itemize}
\ex{}{
Il problema di Cauchy 
\begin{equation*}
    \begin{cases}
        N'(t) = 3N(t) \\
        N(0) = 7
    \end{cases}
\end{equation*}
ammette un'unica soluzione data da $N(t) = ce^{3t}$. Imponendo il dato iniziale otteniamo $N(t) = 7e^{3t}, \forall t \in \mathbb{R}$ (o $\mathbb{R}^+$ se si sta parlando di problema di Cauchy che modellizza un fenomeno fisico).
}

\subsubsection{Equazioni a variabili separabili}

Le equazioni a variabili separabili sono una particolare clase di ED ordinarie del primo ordine
del tipo (1.2.3) che sono caratterizzate dalla presenza di una funzione $f$ prodotto di due funzioni,
una della sola variabile $t$ e l'altra solo dell'incognita $y$. Più nel dettaglio, sono equazioni del
tipo:
\begin{equation}
    y'(t) = a(t)b(y)
\end{equation}
con $a$ funzione continua su un intervallo $I \subset \mathbb{R}$ e $b$ funzione continua su un intervallo $J \subset \mathbb{R}$.
Cerchiamo di capire come determinare l'integrale generale di questo tipo di equazioni.
Distinguiamo due casi:
\begin{itemize}
    \item Se $\overline{y}$ è soluzione dell'equazione $b'(\overline{y}) = 0$ allora $y(t) = \overline{y}$ è soluzione dell'ED (1.2.4). Infatti in tal caso si annulla il secondo membro della (1.2.4) e di conseguenza anche il primo
    membro (perchè la derivata della funzione costante è zero). 
    \item Supponiamo ora che $b(y) \neq 0$. Allora la (1.2.4) può essere riscritta come:
    \begin{equation*}
        \frac{y'}{b(y)} = a(t)
    \end{equation*}
    Quindi un'ipotetica soluzione soddisfa l'identità:
    \begin{equation*}
        \int \frac{y'(t)}{b(y(t))} \; dt = \int a(t) \; dt + C
    \end{equation*}
    Con $C$ costante arbitraria.
    Ora si può effettuare il cambio di variabile dove $y'(t)dt = dy$:
    \begin{equation*}
        \int \frac{dy}{b(y)} = \int a(t) \; dt + C
    \end{equation*}
    Quindi questo è l'integrale generale dell'equazione (1.2.4). Se $B(y)$ è una primitiva di $\frac{1}{b(y)}$ e $A(t)$ è una primitiva di $a(t)$, allora l'integrale generale della ED è assegnato dall'equazione (in forma implicita):
    \begin{equation*}
        B(y) = A(t) + C \; \; \; \text{ con $C$ costante arbitraria}
    \end{equation*}
\end{itemize}
Osserviamo che non è detto che si riesca a ricavare $y$ esplicitamente o a
ridurre la precedente equazione in forma normale.
In generale, per le equazioni a variabili separabili, vale il seguente:
\thm{}{
Si consideri il seguente problema di Cauchy:
\begin{equation*}
    \begin{cases}
        y' = a(t)b(y)\\
        y(t_0) = y_0
    \end{cases}
\end{equation*}
con $a$ continua in un intorno $I$ di $t_0$ e $b$ continua in un intorno $J$ di $y_0$.
Allora esiste un intorno di $t_0$ che denoteremo con $I' \subset I$ e una funzione continua $y$ definita su $I'$ con derivata 
anch'essa continua su $I'$ tale che $y$ sia soluzione del problema di Cauchy.
Inoltre se anche $b'$ è continua su $J$ (o $b$ ha un rapporto incrementale limitato in $J$ anche se non è derivabile) allora tale soluzione è anche unica.
}
\ex{}{
Consideriamo il problema di Cauchy:
\begin{equation*}
    \begin{cases}
        y' = ty^3\\
        y(0) = 1
    \end{cases}
\end{equation*}
Prima di tutto si osserva che $y = 0$ è integrale singolare per l'equazione data. Quindi se $y \neq 0$, separando le variabili e integrando si ottiene: 
\begin{align*}
\int \frac{dy}{y^3} &= \int t dt + C\\
- \frac{1}{2y^2} &= \frac{t^2}{2} + C\\
y &= \pm \frac{1}{\sqrt{C - t^2}}
\end{align*}
Imponendo il dato di Cauchy si osserva che l'unica soluzione è quella che si ottiene per $k = 1$
e considerando il segno positivo davanti alla radice, cioè
\begin{equation*}
    y = \frac{1}{\sqrt{1 - t^2}}
\end{equation*}
}
\ex{}{
Risolvere il problema di Cauchy:
\begin{equation*}
    \begin{cases}
        yy' = 2\\
        y(0) = 1
    \end{cases}
\end{equation*}
Integrando ambo i membri della ED proposta si ottiene:
\begin{equation*}
    \int y \; dy = \int 2 \; dt \Longrightarrow \frac{y^2}{2} = 2t + C \Longrightarrow y = \pm \sqrt{4t + 2C}
\end{equation*}
quindi per ogni $C \in \mathbb{R}$ esistono due soluzioni (corrispondenti ai due segni davanti alla radice)
definite solo per $t \ge -\frac{C}{2}$. Imponendo il dato di Cauchy si ottiene $y(0) = \pm
\sqrt{2C = 1}$,
quindi per compatibilità occorre scegliere il segno positivo davanti alla radice. La soluzione del
problema proposto è dunque $y = 4t + 1$, definita solo per $t \ge -\frac{1}{4}.$
Andiamo a controllare se sono soddisfatte le condizioni del teorema: $a(t) = 2$ che è dunque una
funzione continua e derivabile ovunque; $b(t) = 1/y$ che è continua e derivabile se $y \neq 0$. Quindi
il problema di Cauchy per questa equazione ha una e una sola soluzione purché la condizione
iniziale non sia del tipo $y(t_0) = 0$. Infatti l'equazione non è soddisfatta in questo punto perché
si otterrebbe $0 = 2$. Quindi il problema di Cauchy:
\begin{equation*}
    \begin{cases}
        yy' = 2\\
        y(0) = 1
    \end{cases}
\end{equation*}
\textit{non ha soluzione}. Quindi abbiamo trovato un esempio di problema di Cauchy in cui viene a mancare l'esistenza
di soluzioni. In altre situazioni potrebbe venire a mancare l'unicità delle soluzioni, come
mostra l'esempio successivo.
}

\subsection{Equazioni lineari del primo ordine}

In questa sezione andremo a trattare un caso particolare di ED ordinarie del primo ordine,
il caso in cui $F$ sia una funzione lineare rispetto a $y$ e $y'$.
In questo caso tali equazioni si possono scrivere nella forma:
\begin{equation*}
    a_1(t)y'(t) + a_0(t)y(t) = g(t)
\end{equation*}
con $a_1, a_0, g$ funzioni continue su un intervallo $I \subset \mathbb{R}$.
Se il coefficiente $a_1(t)$ non si annulla, allora l'ED lineare si può scrivere nella forma:
\begin{equation}
    y'(t) + a(t)y(t) = f(t)
\end{equation}
Anche in questo caso supporremo $a$ e $f$ sia funzioni continue su un intervallo $I \subset \mathbb{R}$.
Se $f$ non è identicamente nulla, la (1.3.1) è detta \textbf{equazione completa}. Se $f \equiv 0$ invece, 
l'equazione si dice \textbf{omogenea} e di solito, vista l'importanza che riveste tale equazione nella
struttura dell'integrale generale, si è soliti indicare con una lettera usualmente la $z$, la soluzione di tale equazione, che diventa perciò:
\begin{equation}
    z'(t) + a(t)z(t) = 0
\end{equation}
Vale il seguente teorema:
\thm{}{
    L'integrale generale dell'equazione completa si ottiene aggiungendo all'integrale generale dell'equazione omogenea una particolare soluzione dell'equazione completa.
}
\noindent
Dal teorema $1.3.1$ sappiamo dunque che dobbiamo occuparci prima dello studio dell'equazione omogenea e poi alla ricerca di una soluzione particolare
dell'equazione completa.
\\

\vspace{1em}
\noindent
\textbf{Ricerca dell'integrale generale dell'equazione omeogenea:} 
Sia $A(t)$ una primitiva di $a(t)$ (tale per cui si abbia $A'(t) = a(t)$). Moltiplichiamo entrambi i membri di (1.3.2) per $e^{A(t)}$; si ottiene:
\begin{equation*}
    e^{A(t)}z'(t) + a(t)e^{A(t)}z(t) = 0
\end{equation*}
da cui:
\[\frac{d}{dt}[z(t)e^{A(t)}] = 0\]
e cioè se $z(t)e^{A(t)} =  C$ che si riscrive come:
\begin{equation}
    z(t) = Ce^{-\int a(t) \; dt}
\end{equation} 
\textbf{Ricerca di una soluzione particolare dell'equazione completa:} 
Si utilizza il metodo delle variazioni delle costanti.
L'idea è di ricercare una soluzione simile alla (1.3.3); stavolta però 
$C$ non è più una costante, ma una funzione $C(t)$ da determinare. Cerchiamo
dunque una soluzione della forma:
\[\overline{y}(t) = C(t)e^{-A(t)}\]
La $C(t)$ deve essere determinata in modo tale che $\overline{y}$ così strutturata sia la soluzione
dell'equazione completa (1.3.1). Quindi osserviamo che:
\[\overline{y}'(t) = C'(t)e^{-A(t)} - C(t)a(t)e^{-A(t)}\]
si deduce inserendo le corrispondenti informazioni all'interno dell'equazione completa (1.3.1)
\[e^{-A(t)}[C'(t) - C(t)a(t)] + a(t)C(t)e^{-A(t)} = f(t)\]
cioè
\[e^{-A(t)}C'(t) = f(t)\]
da cui $C'(t) = e^{-A(t)}f(t)$ e dunque:
\[C(t) = \int e^{A(s)}f(s) \; ds\]
Quindi la soluzione particolare dell'equazione completa (1.3.1) è:
\[\overline{y}(t) = e^{-A(t)} \int f(s)e^{A(s)} \; ds\]
Quindi riassumendo l'integrale generale dell'equazione completa (1.3.1) ha la forma:
\begin{equation}
    y(t) = ce^{-A(t)} + e^{-A(t)} \int f(s)e^{A(s)} \; ds 
\end{equation}
\textbf{Risoluzione del problema di Cauchy:} la costante arbitraria nella (1.3.4) 
è determinata dalla condizione iniziale $y(t_0) = y_0$. Scegliendo una primitiva
tale per cui $A(t_0) = 0$ (cioè $A(t) = \int_{t_0}^{t_1} a(s) \; ds$) l'integrale
generale che soddisfa il dato di Cauchy è:
\begin{equation}
    y(t) = e^{-A(t)} \left[ y_0 + \int_{t_0}^t f(s)e^{A(s)} \; ds \right]
\end{equation}
Vale il seguente teorema:
\thm{\textbf{Problema di Cauchy per un'equazione differenziale lineare del primo ordine}}{
    Siano $a, f$ funzioni continue su un intervallo $I \ni t_0$ e sia $y_0 \in \mathbb{R}$. Il problema di Cauchy:
    \begin{equation*}
        \begin{cases}
            y'(t) + a(t)y(t) = f(t)\\
            y(t_0) = y_0
        \end{cases}
    \end{equation*}
    ha una e una sola soluzione $y \in C^1(I)$ (dove $C^k(I)$ è l'insieme delle funzioni continue derivabili fino all'ordine $k$ e con tutte le derivate fino all'ordine $k$ continue); tale soluzione
    è assegnata alla (1.3.5).
}

\subsection{Equazioni differenziali del secondo ordine}

\subsubsection{Generalità}

\dfn{}{
Un'equazione differenziale ordinaria del secondo ordine è un'equazione \textit{lineare} se è del tipo:
\begin{equation}
    y''(t) + a(t)y'(t) + b(t)y(t) = g(t)
\end{equation}
}
\noindent
dove i coefficienti $a_i$ e il termine noto $g$ sono funzioni definite in un certo intervallo $I$ 
e continue nello stesso intervallo. L'equazione si dice omogenea se $g$ è identicamente nullo; in caso 
contrario si dice completa.
L'equazione si dice \textbf{a coefficienti costanti} se i coefficienti $a_i$ sono costanti (per inciso, il termine noto può invece dipendere da t); in caso
contrario si dice \textbf{a coefficienti variabili}. Infine se $a_1$ non si annulla mai, l'equazione si può riscrivere in forma nornmale come:
\begin{equation}
    y''(t) + a(t)y(t) + b(t)y = f(t)
\end{equation}
\textbf{Osservazione:} consideriamo il seguente operatore
\[L: C^2(I) \rightarrow C^0(I)\]
\[L: y \mapsto Ly\]
dove gli spazi $C^k(I)$, sono gli spazi delle funzioni continue derivabili fino all'ordine $k$ e con tutte
le derivate fino all'ordine $k$ continue e dove abbiamo indicato con $Ly$ il primo membro dell'equazione (1.4.1).
Prima di tutto l'operatore è ben definito, perché se $y \in C^2$ si ha che $Ly \in C^0(I)$ e questo grazie alla continuità 
dei coefficienti $a_i$. Inoltre è facile dimostrare che $L$ è un operatore lineare, nel senso che per ogni $\lambda_1, \lambda_2 \in \mathbb{R}$, per ogni $y_1, y_2 \in C^2(I)$ si ha:
\[L(\lambda_1y_1 + \lambda_2y_2) = \lambda_1Ly_1 + \lambda_2Ly_2\]
Questa proprietà dell'operatore $L$ giustifica il motivo per cui l'equazione (1.4.1) è detta lineare.
\ex{}{
    Il più semplice esempio di equazione differenziale del secondo ordine:
    \[y''(t) = 0\]
    Essa naturalmente equivale a dire $y'(t) = C_1$ e da cui $Y(t) = C_1t + C_2$, con $C_1, C_2$ costanti arbitrarie.
    Quindi le soluzioni di questa equazione sono tutte e soli polinomi di primo grado.
}
\ex{\textbf{Oscillatore armonico}}{
    Consideriamo un punto materiale di massa $n$ che rimane libero di muoversi in linea orizzontale,
    attaccato a una molla che esercita una forza di richiamo di tipo elastico. Denotiamo con $y(t)$ la posizione
    del punto sulla retta (rispetto alla configurazione di riposo). Allora si può dimostrare che $y$ soddisfa l'equazione:
    \[my'' = -ky\]
    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[scale=1]
            % Disegno della parete
            \fill[gray!50] (0,0) rectangle (0.5,3);
            \node[below] at (0.25,0) {Parete};
        
            % Disegno della molla
            \draw[line width=1pt] (0.5,1.5) -- (1,1.5);
            \draw[line width=1pt] (1,1.5) 
                .. controls (1.2,1.8) and (1.4,1.2) .. (1.6,1.5)
                .. controls (1.8,1.8) and (2.0,1.2) .. (2.2,1.5);
            \draw[line width=1pt] (2.2,1.5) -- (2.7,1.5);
            \node[above] at (1.4,1.8) {Molla};
        
            % Disegno della massa
            \filldraw[fill=blue!30, draw=blue!70, line width=1pt] (2.7,0.5) rectangle (4.2,2.5);
            \node at (3.45,0.3) {Massa};
        \end{tikzpicture}
    \end{figure}
    dove $k > 0$ denota la costante elastica del sistema. Siccome ovviamente $m \neq 0$, allora si può riscrivere
    l'equazione in forma normale come:
    \begin{equation}
        y'' + \omega^2y = 0
    \end{equation}
    dove $\omega^2 = \frac{k}{m} > 0$. L'equazione prende il nome dell'oscillatore armonico.
    L'equazione (1.4.3) è un'equazione differenziale lineare del secondo ordine omogenea e a coefficienti costanti. Se sul
    punto agisce una forza esterna (dipendente solo dal tempo $t$) l'equazione si riscrive come:
    \[y'' + \omega^2y = f(t)\]
    nel caso venga presa in considerazione lo smorzamento dovuto all'attrito, l'equazione si trasforma in
    \[y'' + hy' + \omega^2y = 0\]
    con $h > 0$. 

}
\end{document}