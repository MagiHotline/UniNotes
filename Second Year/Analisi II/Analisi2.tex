\documentclass[a4paper]{article}
\usepackage{import}
\input{../../setup.sty}
% Set custom margins
\onehalfspacing

\geometry{a4paper, margin=1in}
\geometry{letterpaper, left=1.5in, right=1in, top=1in, bottom=1in}

\title{Analisi II}
\author{Università di Verona\\Imbriani Paolo - VR500437\\Professor Zivcovich Franco}

% Make section titles bigger
\titleformat{\section}[hang]{\huge\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}[hang]{\Large\normalfont\itshape}{\thesubsection}{1em}{}

\usepackage[italian]{babel}

\addto\captionsitalian{% Replace "english" with the language you use
  \renewcommand{\contentsname}%
    {Indice}%
}

\numberwithin{equation}{subsection}

\begin{document}

\begin{figure}
    \centering
    \includegraphics[width=0.3\textwidth]{../UniversityofVerona.png}
\end{figure}

\maketitle 

\pagebreak

\tableofcontents

\pagebreak

\section{Equazioni differenziali}

\subsection{Modelli differenziali}

I fisici, per descrivere dei fenomeni, usano la matematica come strumento per formalizzare dei modelli naturali e in particolare vorrei concentrarmi sull'uso delle equazioni differenziali. 
Per esempio, si denota $x(t)$ lo spostamento nel tempo.
Con la derivata prima $x'(t)$ si denota la velocità della particella in quell'istante e con la derivata seconda $x''(t)$ l'accelerazione.
Quindi quando andiamo a tradurre
matematicamente le leggi che governano modelli naturali può essere naturale dover lavorare
con equazioni che coinvolgono una funzione incognita e qualcuna delle sue derivate.

\ex{}{La seconda legge del moto di Newton $F = ma$, che stabilisce la posizione
$x(t)$ al tempo $t$ di un corpo di massa m costante, soggetto a una forza $F(t)$, deve soddisfare
l'equazione differenziale:
\[m\frac{d^2x}{dt^2} = F(t) \; \; \text{equazione del moto}\]
}
\noindent
Quindi le equazioni differenziali nascono per descrivere fenomeni fisici e naturali. 
Possono essere classificate in modi diversi. Abbiamo infatti:
\begin{enumerate}
    \item \textit{Equazioni differenziali ordinarie} (ODE) se vengono coinvolte solo le derivate rispetto ad una sola variabile oppure \textit{equazioni differenziali parziali} (PDE) se vengono coinvolte derivate parziali
     dell'incognita rispetto a più variabili.
     \ex{}{L'equazione: \[\frac{\partial^2 u}{\partial t^2}=c^2 \frac{\partial^2u}{\partial x^2}\]
     rappresenta l'equazione delle onde che modellizza lo spostamento trasversale $u(x, t)$ nel
punto $x$ al tempo $t$ di una corda tesa che può vibrare.
     }
    \item Classificazione in base all'ordine: l'ordine di una ED è l'ordine massimo di derivazione che
    compare nell'equazione.
\ex{}{L'equazione: \[\frac{dy^2}{dt^2} + ty^3 - \cos{y} = \sin{t} \; \; \; \; \; \; \text{è di ordine 2}\]
 \[\frac{d^3y}{dt^3} - 2t\left(\frac{dy}{dt}\right)^2  = y \frac{dy^2}{dt^2} - e^t\; \; \; \; \; \; \text{è di ordine 3}\]
}
Possiamo dunque formalizzare i concetti finora introdotti attraverso la seguente definizione:
\end{enumerate}
\dfn{Equazione differenziale}{
Si dice \textbf{equazione differenziale} di ordine $n$ un'equazione del tipo
\begin{equation}
    F(t,y',y'', \dots , y^{(n)}) = 0   
\end{equation}
dove $y(t)$ è la funzione incognita e $F$ è una funzione assegnata delle $n + 2$ variabili $t, y, y'
, \dots , y(n)$ a valori reali.
\\
Si dice \textbf{ordine} di un'equazione differenziale il massimo ordine di derivazione che compare nell'equazione.\\
Si dice \textbf{soluzione (o curva integrale)} di (1.1.1) nell'intervallo $I \subset \mathbb{R}$ una funzione $\varphi$, definita almeno in $I$ e a valori reali per cui risulti:
\begin{equation*}
F(t, \varphi'(t), \varphi''(t), \dots , \varphi^{(n)}(t)) = 0 \; \; \; \; \; \; \forall t \in I
\end{equation*}
Infine si dice integrale generale dell'equazione (1.1.1) una formula che rappresenti la famiglia
di tutte le soluzioni dell'equazione (1.1.1), eventualmente al variare di uno o più parametri in essa
contenuti.
}
\ex{}{
Consideriamo una popolazione di individui, animali o vegetali che siano,
e sia $N(t)$ il numero degli individui. Osserviamo che N è funzione di del tempo $t$, assume solo
valori interi ed è a priori una funzione discontinua di t; tuttavia può essere approssimata da
una funzione continua e derivabile purché il numero degli individui sia abbastanza grande.
Supponiamo che la popolazione sia isolata e che la proporzione degli individui in età riproduttiva e la fecondità siano costanti.
Se escludiamo i casi di morte, immigrazione, emigrazione, allora il tasso di accrescimento coincide con quello di natalità 
e se indichiamo con $\lambda$ il tasso specifico di natalità (i.e. il numero
di nati per unità di tempo) l'equazione che descrive il modello diventa:
\[\frac{dN}{dt} = \lambda N(t)\]
Questo processo risulta realistico solo in popolazioni che crescono in situazioni ideali e sono
assenti tutti i fattori che ne impediscono la crescita.
}
La stessa equazione compare anche in altri modelli relativi a sistemi fisiologici ed ecologici.
\ex{}{Studiamo ora il modello di crescita (dovuto a Malthus, 1978) relativo
all'evoluzione di una popolazione isolata in presenza di risorse limitate ed in assenza di predatori
o antagonisti all'utilizzo delle risorse. In questo caso l'equazione che si ottiene è la seguente:
\begin{equation*}
    \frac{dN}{dt} = \lambda N(t) - \mu N(t)
\end{equation*}
dove come prima $\lambda$ è il tasso di natalità mentre $\mu$ è il tasso di mortalità (cioè rispettivamente
il numero di nati e morti nell'unità di tempo). Il numero $\varepsilon = \lambda - \mu$ è detto \textbf{potenziale
biologico.}
}
\noindent
Ci chiediamo ora come possiamo trovare una soluzione del problema studiato nell'Esempio
1.5. Supponiamo per il momento che sia $N \neq 0$. Allora:
\begin{equation*}
N = \varepsilon N = \frac{N}{N} = \varepsilon \Longrightarrow \frac{d}{dt} (\log{|N|}) = \varepsilon,
\end{equation*}
da cui otteniamo:
\begin{equation*}
\log{|N(t)|} = \varepsilon t + c_1 \Longrightarrow |N(t)| = e^{c_1}e^{\varepsilon t} =: k^2 e^{\varepsilon t}
\end{equation*}
dove abbiamo posto $e^{c_1} =: k^2 > 0$ costante positiva e arbitraria. A questo punto allora:
\[N(t) = \pm k^2e^{\varepsilon t}\]
Quindi possiamo dire sicuramente che:
\[N(t) = Ce^{\varepsilon t} \; \; \; C \in \mathbb{R} \backslash \{0\} \]
Tutto questo vale se $N \neq 0$; ma è banale verificare che anche $N = 0$ soddisfa l'equazione di
partenza, quindi possiamo dire che l'integrale generale è:
\[N(t) = Ce^{\varepsilon t} = Ce^{(\lambda - \mu)t} \; \; \; C \in \mathbb{R}\]
In particolare dall'ultima riga leggiamo che:
\begin{enumerate}
    \item Se $\lambda > \mu$ allora $N(t)$ è una funzione che cresce in maniera esponenziale.
    \item Se $\lambda < \mu$ allora $N(t)$ è una funzione che decresce fino ad estinguersi. 
    \item Se $\lambda = \mu$ allora $N(t)$ è una funzione stabile nel tempo.
\end{enumerate}
Osserviamo in particolare che non abbiamo trovato solo una soluzione, ma infinite soluzioni,
dipendenti da una costante arbitraria.

\subsection{Equazioni differenziali di primo ordine}

\subsubsection{Generalità}

Le equazioni differenziali di primo ordine sono le più semplici da trattare e sono di fondamentale importanza in quanto sono alla base di molte applicazioni pratiche.
Esse sono della forma:
\begin{equation}
    F(t, y, y') = 0
\end{equation}
con $F$ funzione assegnata delle tre variabili $t, y, y'$ a valori reali.
\ex{}{
    La ricerca delle primitive di una funzione $f$ continua su un intervallo $I$
    equivale a risolvere l'equazione differenziale $y'(t) = f(t)$ che ammette infinite soluzioni del tipo
\begin{equation*}
    y(t) = \int f(t) \; dt + C \; \; \; \; \; \; C \in \mathbb{R}
\end{equation*}
}
\noindent
\textbf{Si dimostra} che l'insieme delle soluzioni di una EDO del primo ordine è costituito da una famiglia di funzioni dipendenti da un parametro 
$C: t \mapsto \varphi(t; c)$. Tale famiglia prende il nome di \textbf{integrale generale} dell'equazione differenziale.
La condizione supplementare $y(t_0) = y_0$ permette di selezionare una soluzione specifica.
\dfn{Problema di Cauchy}{
Il problema di risolvere il seguente sistema di equazioni:
\begin{equation}
\begin{cases}
    F(t, y, y') = 0 \\
    y(t_0) = y_0
\end{cases}
\end{equation}
prende il nome di \textbf{problema di Cauchy}.
}
\dfn{Forma Normale}{
Un'equazione differenziale ordinaria del primo ordine si dice in \textbf{forma normale} se è scritta nella forma:
\begin{equation}
    y'(t) = f(t, y)
\end{equation}
}
\noindent
Per equazioni di questo tipo si può assicurare, sotto larghe ipotesi, che il problema di Cauchy (1.2.2) ammette un'unica soluzione almeno 
localmente (cioè per valori di $t$ in un intorno di $t_0$).
\\
Le soluzioni dell'ED espresse dall'integrale generale potrebbero talvolta
essere definite su insiemi diversi a seconda del valore della costante o anche su insiemi più complicati
di un intervallo (es. $t \neq 0$). Tuttavia quando parleremo di soluzione del problema di Cauchy andremo
sempre a intendere una funzione che:
\begin{itemize}
    \item[a)] è definita su un intervallo $I$ contenente $t_0$ in cui è assegnata la condizione iniziale.
    \item[b)] è derivabile in ogni punto di $I$ e soddisfa l'equazione in ogni punto di $I$. 
\end{itemize}
\ex{}{
Il problema di Cauchy 
\begin{equation*}
    \begin{cases}
        N'(t) = 3N(t) \\
        N(0) = 7
    \end{cases}
\end{equation*}
ammette un'unica soluzione data da $N(t) = ce^{3t}$. Imponendo il dato iniziale otteniamo $N(t) = 7e^{3t}, \forall t \in \mathbb{R}$ (o $\mathbb{R}^+$ se si sta parlando di problema di Cauchy che modellizza un fenomeno fisico).
}

\subsubsection{Equazioni a variabili separabili}

Le equazioni a variabili separabili sono una particolare clase di ED ordinarie del primo ordine
del tipo (1.2.3) che sono caratterizzate dalla presenza di una funzione $f$ prodotto di due funzioni,
una della sola variabile $t$ e l'altra solo dell'incognita $y$. Più nel dettaglio, sono equazioni del
tipo:
\begin{equation}
    y'(t) = a(t)b(y)
\end{equation}
con $a$ funzione continua su un intervallo $I \subset \mathbb{R}$ e $b$ funzione continua su un intervallo $J \subset \mathbb{R}$.
Cerchiamo di capire come determinare l'integrale generale di questo tipo di equazioni.
Distinguiamo due casi:
\begin{itemize}
    \item Se $\overline{y}$ è soluzione dell'equazione $b'(\overline{y}) = 0$ allora $y(t) = \overline{y}$ è soluzione dell'ED (1.2.4). Infatti in tal caso si annulla il secondo membro della (1.2.4) e di conseguenza anche il primo
    membro (perchè la derivata della funzione costante è zero). 
    \item Supponiamo ora che $b(y) \neq 0$. Allora la (1.2.4) può essere riscritta come:
    \begin{equation*}
        \frac{y'}{b(y)} = a(t)
    \end{equation*}
    Quindi un'ipotetica soluzione soddisfa l'identità:
    \begin{equation*}
        \int \frac{y'(t)}{b(y(t))} \; dt = \int a(t) \; dt + C
    \end{equation*}
    Con $C$ costante arbitraria.
    Ora si può effettuare il cambio di variabile dove $y'(t)dt = dy$:
    \begin{equation*}
        \int \frac{dy}{b(y)} = \int a(t) \; dt + C
    \end{equation*}
    Quindi questo è l'integrale generale dell'equazione (1.2.4). Se $B(y)$ è una primitiva di $\frac{1}{b(y)}$ e $A(t)$ è una primitiva di $a(t)$, allora l'integrale generale della ED è assegnato dall'equazione (in forma implicita):
    \begin{equation*}
        B(y) = A(t) + C \; \; \; \text{ con $C$ costante arbitraria}
    \end{equation*}
\end{itemize}
Osserviamo che non è detto che si riesca a ricavare $y$ esplicitamente o a
ridurre la precedente equazione in forma normale.
In generale, per le equazioni a variabili separabili, vale il seguente:
\thm{}{
Si consideri il seguente problema di Cauchy:
\begin{equation*}
    \begin{cases}
        y' = a(t)b(y)\\
        y(t_0) = y_0
    \end{cases}
\end{equation*}
con $a$ continua in un intorno $I$ di $t_0$ e $b$ continua in un intorno $J$ di $y_0$.
Allora esiste un intorno di $t_0$ che denoteremo con $I' \subset I$ e una funzione continua $y$ definita su $I'$ con derivata 
anch'essa continua su $I'$ tale che $y$ sia soluzione del problema di Cauchy.
Inoltre se anche $b'$ è continua su $J$ (o $b$ ha un rapporto incrementale limitato in $J$ anche se non è derivabile) allora tale soluzione è anche unica.
}
\ex{}{
Consideriamo il problema di Cauchy:
\begin{equation*}
    \begin{cases}
        y' = ty^3\\
        y(0) = 1
    \end{cases}
\end{equation*}
Prima di tutto si osserva che $y = 0$ è integrale singolare per l'equazione data. Quindi se $y \neq 0$, separando le variabili e integrando si ottiene: 
\begin{align*}
\int \frac{dy}{y^3} &= \int t dt + C\\
- \frac{1}{2y^2} &= \frac{t^2}{2} + C\\
y &= \pm \frac{1}{\sqrt{C - t^2}}
\end{align*}
Imponendo il dato di Cauchy si osserva che l'unica soluzione è quella che si ottiene per $k = 1$
e considerando il segno positivo davanti alla radice, cioè
\begin{equation*}
    y = \frac{1}{\sqrt{1 - t^2}}
\end{equation*}
}
\ex{}{
Risolvere il problema di Cauchy:
\begin{equation*}
    \begin{cases}
        yy' = 2\\
        y(0) = 1
    \end{cases}
\end{equation*}
Integrando ambo i membri della ED proposta si ottiene:
\begin{equation*}
    \int y \; dy = \int 2 \; dt \Longrightarrow \frac{y^2}{2} = 2t + C \Longrightarrow y = \pm \sqrt{4t + 2C}
\end{equation*}
quindi per ogni $C \in \mathbb{R}$ esistono due soluzioni (corrispondenti ai due segni davanti alla radice)
definite solo per $t \ge -\frac{C}{2}$. Imponendo il dato di Cauchy si ottiene $y(0) = \pm
\sqrt{2C = 1}$,
quindi per compatibilità occorre scegliere il segno positivo davanti alla radice. La soluzione del
problema proposto è dunque $y = 4t + 1$, definita solo per $t \ge -\frac{1}{4}.$
Andiamo a controllare se sono soddisfatte le condizioni del teorema: $a(t) = 2$ che è dunque una
funzione continua e derivabile ovunque; $b(t) = 1/y$ che è continua e derivabile se $y \neq 0$. Quindi
il problema di Cauchy per questa equazione ha una e una sola soluzione purché la condizione
iniziale non sia del tipo $y(t_0) = 0$. Infatti l'equazione non è soddisfatta in questo punto perché
si otterrebbe $0 = 2$. Quindi il problema di Cauchy:
\begin{equation*}
    \begin{cases}
        yy' = 2\\
        y(0) = 1
    \end{cases}
\end{equation*}
\textit{non ha soluzione}. Quindi abbiamo trovato un esempio di problema di Cauchy in cui viene a mancare l'esistenza
di soluzioni. In altre situazioni potrebbe venire a mancare l'unicità delle soluzioni, come
mostra l'esempio successivo.
}

\subsection{Equazioni lineari del primo ordine}

In questa sezione andremo a trattare un caso particolare di ED ordinarie del primo ordine,
il caso in cui $F$ sia una funzione lineare rispetto a $y$ e $y'$.
In questo caso tali equazioni si possono scrivere nella forma:
\begin{equation*}
    a_1(t)y'(t) + a_0(t)y(t) = g(t)
\end{equation*}
con $a_1, a_0, g$ funzioni continue su un intervallo $I \subset \mathbb{R}$.
Se il coefficiente $a_1(t)$ non si annulla, allora l'ED lineare si può scrivere nella forma:
\begin{equation}
    y'(t) + a(t)y(t) = f(t)
\end{equation}
Anche in questo caso supporremo $a$ e $f$ sia funzioni continue su un intervallo $I \subset \mathbb{R}$.
Se $f$ non è identicamente nulla, la (1.3.1) è detta \textbf{equazione completa}. Se $f \equiv 0$ invece, 
l'equazione si dice \textbf{omogenea} e di solito, vista l'importanza che riveste tale equazione nella
struttura dell'integrale generale, si è soliti indicare con una lettera usualmente la $z$, la soluzione di tale equazione, che diventa perciò:
\begin{equation}
    z'(t) + a(t)z(t) = 0
\end{equation}
Vale il seguente teorema:
\thm{}{
    L'integrale generale dell'equazione completa si ottiene aggiungendo all'integrale generale dell'equazione omogenea una particolare soluzione dell'equazione completa.
}
\noindent
Dal teorema $1.3.1$ sappiamo dunque che dobbiamo occuparci prima dello studio dell'equazione omogenea e poi alla ricerca di una soluzione particolare
dell'equazione completa.
\\

\vspace{1em}
\noindent
\textbf{Ricerca dell'integrale generale dell'equazione omeogenea:} 
Sia $A(t)$ una primitiva di $a(t)$ (tale per cui si abbia $A'(t) = a(t)$). Moltiplichiamo entrambi i membri di (1.3.2) per $e^{A(t)}$; si ottiene:
\begin{equation*}
    e^{A(t)}z'(t) + a(t)e^{A(t)}z(t) = 0
\end{equation*}
da cui:
\[\frac{d}{dt}[z(t)e^{A(t)}] = 0\]
e cioè se $z(t)e^{A(t)} =  C$ che si riscrive come:
\begin{equation}
    z(t) = Ce^{-\int a(t) \; dt}
\end{equation} 
\textbf{Ricerca di una soluzione particolare dell'equazione completa:} 
Si utilizza il metodo delle variazioni delle costanti.
L'idea è di ricercare una soluzione simile alla (1.3.3); stavolta però 
$C$ non è più una costante, ma una funzione $C(t)$ da determinare. Cerchiamo
dunque una soluzione della forma:
\[\overline{y}(t) = C(t)e^{-A(t)}\]
La $C(t)$ deve essere determinata in modo tale che $\overline{y}$ così strutturata sia la soluzione
dell'equazione completa (1.3.1). Quindi osserviamo che:
\[\overline{y}'(t) = C'(t)e^{-A(t)} - C(t)a(t)e^{-A(t)}\]
si deduce inserendo le corrispondenti informazioni all'interno dell'equazione completa (1.3.1)
\[e^{-A(t)}[C'(t) - C(t)a(t)] + a(t)C(t)e^{-A(t)} = f(t)\]
cioè
\[e^{-A(t)}C'(t) = f(t)\]
da cui $C'(t) = e^{-A(t)}f(t)$ e dunque:
\[C(t) = \int e^{A(s)}f(s) \; ds\]
Quindi la soluzione particolare dell'equazione completa (1.3.1) è:
\[\overline{y}(t) = e^{-A(t)} \int f(s)e^{A(s)} \; ds\]
Quindi riassumendo l'integrale generale dell'equazione completa (1.3.1) ha la forma:
\begin{equation}
    y(t) = ce^{-A(t)} + e^{-A(t)} \int f(s)e^{A(s)} \; ds 
\end{equation}
\textbf{Risoluzione del problema di Cauchy:} la costante arbitraria nella (1.3.4) 
è determinata dalla condizione iniziale $y(t_0) = y_0$. Scegliendo una primitiva
tale per cui $A(t_0) = 0$ (cioè $A(t) = \int_{t_0}^{t_1} a(s) \; ds$) l'integrale
generale che soddisfa il dato di Cauchy è:
\begin{equation}
    y(t) = e^{-A(t)} \left[ y_0 + \int_{t_0}^t f(s)e^{A(s)} \; ds \right]
\end{equation}
Vale il seguente teorema:
\thm{\textbf{Problema di Cauchy per un'equazione differenziale lineare del primo ordine}}{
    Siano $a, f$ funzioni continue su un intervallo $I \ni t_0$ e sia $y_0 \in \mathbb{R}$. Il problema di Cauchy:
    \begin{equation*}
        \begin{cases}
            y'(t) + a(t)y(t) = f(t)\\
            y(t_0) = y_0
        \end{cases}
    \end{equation*}
    ha una e una sola soluzione $y \in C^1(I)$ (dove $C^k(I)$ è l'insieme delle funzioni continue derivabili fino all'ordine $k$ e con tutte le derivate fino all'ordine $k$ continue); tale soluzione
    è assegnata alla (1.3.5).
}

\subsection{Equazioni differenziali del secondo ordine}

\subsubsection{Generalità}

\dfn{}{
Un'equazione differenziale ordinaria del secondo ordine è un'equazione \textit{lineare} se è del tipo:
\begin{equation}
    y''(t) + a(t)y'(t) + b(t)y(t) = g(t)
\end{equation}
}
\noindent
dove i coefficienti $a_i$ e il termine noto $g$ sono funzioni definite in un certo intervallo $I$ 
e continue nello stesso intervallo. L'equazione si dice omogenea se $g$ è identicamente nullo; in caso 
contrario si dice completa.
L'equazione si dice \textbf{a coefficienti costanti} se i coefficienti $a_i$ sono costanti (per inciso, il termine noto può invece dipendere da t); in caso
contrario si dice \textbf{a coefficienti variabili}. Infine se $a_1$ non si annulla mai, l'equazione si può riscrivere in forma nornmale come:
\begin{equation}
    y''(t) + a(t)y(t) + b(t)y = f(t)
\end{equation}
\textbf{Osservazione:} consideriamo il seguente operatore
\[L: C^2(I) \rightarrow C^0(I)\]
\[L: y \mapsto Ly\]
dove gli spazi $C^k(I)$, sono gli spazi delle funzioni continue derivabili fino all'ordine $k$ e con tutte
le derivate fino all'ordine $k$ continue e dove abbiamo indicato con $Ly$ il primo membro dell'equazione (1.4.1).
Prima di tutto l'operatore è ben definito, perché se $y \in C^2$ si ha che $Ly \in C^0(I)$ e questo grazie alla continuità 
dei coefficienti $a_i$. Inoltre è facile dimostrare che $L$ è un operatore lineare, nel senso che per ogni $\lambda_1, \lambda_2 \in \mathbb{R}$, per ogni $y_1, y_2 \in C^2(I)$ si ha:
\[L(\lambda_1y_1 + \lambda_2y_2) = \lambda_1Ly_1 + \lambda_2Ly_2\]
Questa proprietà dell'operatore $L$ giustifica il motivo per cui l'equazione (1.4.1) è detta lineare.
\ex{}{
    Il più semplice esempio di equazione differenziale del secondo ordine:
    \[y''(t) = 0\]
    Essa naturalmente equivale a dire $y'(t) = C_1$ e da cui $Y(t) = C_1t + C_2$, con $C_1, C_2$ costanti arbitrarie.
    Quindi le soluzioni di questa equazione sono tutte e soli polinomi di primo grado.
}
\ex{\textbf{Oscillatore armonico}}{
    Consideriamo un punto materiale di massa $n$ che rimane libero di muoversi in linea orizzontale,
    attaccato a una molla che esercita una forza di richiamo di tipo elastico. Denotiamo con $y(t)$ la posizione
    del punto sulla retta (rispetto alla configurazione di riposo). Allora si può dimostrare che $y$ soddisfa l'equazione:
    \[my'' = -ky\]
    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[scale=1]
            % Disegno della parete
            \fill[gray!50] (0,0) rectangle (0.5,3);
            \node[below] at (0.25,0) {Parete};
        
            % Disegno della molla
            \draw[line width=1pt] (0.5,1.5) -- (1,1.5);
            \draw[line width=1pt] (1,1.5) 
                .. controls (1.2,1.8) and (1.4,1.2) .. (1.6,1.5)
                .. controls (1.8,1.8) and (2.0,1.2) .. (2.2,1.5);
            \draw[line width=1pt] (2.2,1.5) -- (2.7,1.5);
            \node[above] at (1.4,1.8) {Molla};
        
            % Disegno della massa
            \filldraw[fill=blue!30, draw=blue!70, line width=1pt] (2.7,0.5) rectangle (4.2,2.5);
            \node at (3.45,0.3) {Massa};
        \end{tikzpicture}
    \end{figure}
    dove $k > 0$ denota la costante elastica del sistema. Siccome ovviamente $m \neq 0$, allora si può riscrivere
    l'equazione in forma normale come:
    \begin{equation}
        y'' + \omega^2y = 0
    \end{equation}
    dove $\omega^2 = \frac{k}{m} > 0$. L'equazione prende il nome dell'oscillatore armonico.
    L'equazione (1.4.3) è un'equazione differenziale lineare del secondo ordine omogenea e a coefficienti costanti. Se sul
    punto agisce una forza esterna (dipendente solo dal tempo $t$) l'equazione si riscrive come:
    \[y'' + \omega^2y = f(t)\]
    nel caso venga presa in considerazione lo smorzamento dovuto all'attrito, l'equazione si trasforma in
    \[y'' + hy' + \omega^2y = 0\]
    con $h > 0$. 
    Sarà chiaro in seguito che l'integrale generale di una qualunque equazione lineare del secondo ordine dipende da due parametri
    arbitrarie. Quindi per determinare una soluzione specifica è necessario conoscere due condizioni iniziali.
}
\dfn{}{
    Si dice \textbf{problema di Cauchy} per un'equazione differenziale lineare del secondo ordine (per semplicità la consideriamo espressa in forma normale), il problema
    \begin{equation}
        \begin{cases}
            y''(t) + a(t)y'(t) + b(t)y(t) = g(t)\\
            y(t_0) = y_0\\
            y'(t_0) = y'_0
        \end{cases}
    \end{equation}
}
\thm{Esistenza e unicità per il problema di Cauchy (1.4.4)}{
    Siano $a, b, f$ funzioni continue in un intervallo $I \ni t_0$. Allora per ogni
    $y_0, y_1 \in \mathbb{R}$ il problema di Cauchy (1.4.4) ha una e una sola soluzione $y \in C^2(I)$. 
}
\noindent
Questo risultato è analogo al corrispondente enunciato per le equazioni differnziali lineari del primo ordine.
Anche in questo caso, la soluzione sarà ottenuta imponendo le condizioni iniziali nell'espressione che individua l'integrale generale dell'equazione (1.4.1).
Quindi il problema si riduce a comprendere come si possa determinare l'integrale generale dell'equazione differenziale lineare del secondo ordine (1.4.1).

\subsubsection{La struttura dell'integrale generale}

L'equazione $Lz = 0$ si dice \textit{equazione omogenea} associata all'
equazione completa $Ly = f$. Il seguente teorema permette di determinare facilmente
la struttura dell'integrale generale dell'equazione (1.4.1). Questo risultato 
non usa il fatto che $Ly = f$ sia un'equazione differenziale e non dipende dall'ordine 
dell'equazione, sfrutta solamente il fatto che $L$ sia un operatore lineare.

\thm{\textbf{Struttura dell'integrale generale dell'equazione linaere completa}}{
    Si può dimostrare che:
    \begin{enumerate}
        \item L'insieme delle soluzioni all'equazione omogenea $Lz = 0$ in un dato intervallo $I$ è uno spazio vettoriale di dimensione 2 (sottospazio di $C^2(I)$).
        \item L'integrale generale dell'equazione completa si ottiene sommando l'integrale generale dell'equazione omeogene
        e una soluzione particolare dell'equazione completa.
    \end{enumerate}
}
\ex{}{
    Si consideri l'equazione $t^2z'' - 3tz' + 3z = 0$. Sia $z_1 = t$. Allora
    $z_1'(t) = 1, z_2''(t) = 0$ da cui $t^20- 3t \, 1 + 3t = -3t + 3t = 0$; quindi $z_1$ è una soluzione dellì'equazione data.
    Sia ora $z_2 = t^3$. Allora $z_2'(t) = 3t^2, z_2''(t) = 6t$ da cui inserendo le informazioni nell'equazione si ottiene 
    $t^26t-3t3t^2 + 3t^3 = 6t^3 - 9t^3 + 3t^3 = 0$; quindi $z_2$ è una soluzione dell'equazione data.
    Le due soluzioni sono linearmente indipendenti, quindi l'integrale generale dell'equazione data è:
    \[z(t) = C_1t + C_2t^3\]
    al variare di $C_1, C_2 \in \mathbb{R}$. 
}
\noindent
Nel caso precendente è particolarmente facile vedere che le due soluzioni proposte sono linearmente indipendenti; 
In generale può non essere così immediato. Il seguente critico generale permette di decidere qualora due soluzioni
proposte siano o meno linearmente indipendenti.
\thm{\textbf{Determinante wroskiano e indipendenza}}{
    Siano $z_1, z_2$ due funzioni $C^2(I)$ soluzioni dell'equazione lineare omogenea:
    \[Lz \equiv z'' + a(t)z' + b(t) = 0\]
    nell'intervallo $I$. Allora esse sono linearmente indipendenti in $C^2(I)$ se e soltanto se la seguente matrice:
    \[W(t) = \begin{pmatrix}
        z_1(t) & z_2(t)\\
        z_1'(t) & z_2'(t)
    \end{pmatrix}\]
    detta \textbf{matrice Wronskiana} ha \textit{determinante} diverso da zero per ogni $t \in I$ (dalla regolarità delle soluzioni, 
    è sufficiente che il determinante di tale matrice sia diverso da zero in un punto $t_0 \in I$). 
}
\noindent
\textbf{Quindi} per determinare l'integrale generale dell'equazione lineare completa occorre:
\begin{enumerate}
    \item Determinare l'integrale generale dell'equazione omogenea, quindi serve determinare due soluzioni $z_1(t), z_2(t)$ dell'equazione omogenea linearmente indipendenti;
    \item Determinare una soluzione particolare dell'equazione completa. A questo punto l'integrale generale dell'equazione completa è dato da:
    \[\overline{y}(t) + C_1z_1(t) + C_2z_2(t)\]
    al variare di $C_1, C_2 \in \mathbb{R}$. 
\end{enumerate}

\subsubsection{Equazioni differenziali del secondo ordine omogenee a coefficienti costanti}

Consideriamo l'equazione differenziale lineare omogenea del secondo ordine a coefficienti costanti:
\[z''(t) + az'(t) + bz(t) = 0 \; \; \text{ con $a, b$ costanti}\]
In analogia con il caso delle equazioni differenziali del primo ordine, che ammette gli esponenziali come soluzioni, si cerca
anche qui una soluzione del tipo $t \mapsto e^{rt}$ con $r \in \mathbb{C}$. Sostituendo tale soluzione nell'equazione omogenea si ottiene:
\[z'(t) = re^{rt} \; \; \; \; \; \; \; \; z''(t) = r^2e^{rt}\]
\[e^{rt}(r^2 + ar + b) = 0\]
Siccome l'esponenziale è sempre positiva, affinché l'equazione precedente abbia soluzione
è necessario che la costante $r$ sia una radice dell'equazione di secondo grado:
\[r^2 + ar + b = 0\]
che viene detta equazioen caratteristica dell'equazione differenziale. Si possono avere tre casi in base al segno del discriminante:

\begin{figure}[H]
\centering
\begin{tabular}{|c|c|c|}
    \hline
    Discriminante & Soluzione 1 & Soluzione 2\\
    \hline
    $\Delta > 0$ & $e^{r_1t}$ & $e^{r_2t}$\\
    $\Delta = 0$ & $e^{rt}$ & $te^{rt}$\\
    $\Delta < 0$ & $e^{\alpha t}\cos{\beta t}$ & $e^{\alpha t}\sin{\beta t}$ \\
    \hline
\end{tabular}
\end{figure}

\ex{}{
    \textit{Risolvere il seguente problema di Cauchy:}
    \begin{equation*}
        \begin{cases}
            z'' - 2z' - 3z = 0\\
            z(0) = 1\\
            z'(0) = 2
        \end{cases}
    \end{equation*}
    L'equazione proposta è differenziale ordinaria del secondo ordine lineare, a coefficienti
    costanti e omogenea. La sua equazione caratteristica è:
    \[r^2 - 2r - 3 = 0\]
    che ha soluzioni $r_1 = 3, r_2 = -1$. Quindi l'integrale generale dell'equazione omogenea è:
    \[z(t) = C_1e^{3t} + C_2e^{-t}\]
    al variare di $C_1, C_2 \in \mathbb{R}$. Imponendo le condizioni iniziali si ottiene:
    \[z(0) = C_1 + C_2 = 1\]
    \[z'(0) = 3C_1 - C_2 = 2\]
    da cui 
    \[
    \begin{cases}
        C_1 + C_2 = 1\\
        -C_1 + 3C_2 = 2
    \end{cases} \Longrightarrow 
    \begin{cases}
        C_1 = \frac{1}{4}\\
        C_2 = \frac{3}{4}
    \end{cases}
    \]
    Quindi la soluzione del problema di Cauchy proposto è:
    \[z(t) = \frac{1}{4}e^{3t} + \frac{3}{4}e^{-t}\]
}

\subsubsection{Equazioni lineari del secondo ordine non omogenee: Metodo di somiglianza}

Consideriamo l'equazione differenziale lineare del secondo ordine a coefficienti costanti:
\[y''(t) + ay'(t) + by(t) = f(t) \; \; \text{ con $a, b$ costanti}\]
nel caso in cui il termine noto $f$ abbia una forma particolare. 
Un metodo più generale si basa sul metodo di variazione delle costanti, che permette di determinare una soluzione particolare dell'equazione completa.
Quando $f$ è semplice si cerca una soluzione che \textit{assomiglia} nel senso che andremo a specificare:
\begin{itemize}
    \item Se $f(t) = p_r(t)$ è un polinomio di grado $r$, si cerca una soluzione che sia anch'essa un polinomio, con le seguenti caratteristiche:
    \begin{figure}[H]
        \centering
        \begin{tabular}{|c|c|}
            \hline
            $\overline{y}(t) = q_r(t)$ & se $b \neq 0$\\
            $\overline{y}(t) = tq_r(t)$ & se $b = 0$ e $a \neq 0$\\
            $\overline{y}(t) = t^2q_r(t)$ & se $b = 0$ e $a = 0$\\
            \hline
        \end{tabular}
    
    \end{figure}
    \item Se $f(t) = Ae^{\lambda t}$ con $\lambda \in \mathbb{C}$. In tal caso, si cerca una soluzione del tipo:
    $y(t) = e^{\lambda t}\gamma(t)$ con $\gamma(t)$ polinomio di grado opportuno.
    \item Se infine $\lambda^2 + a\lambda + b = 0$ e $2\lambda + a = 0$ allora si ha $\gamma(t) = A$ da cui:
    \[\gamma(t) = \frac{A}{2}t^2 \; \; \; \; \; \;  \overline{y}(t) = \frac{A}{2}t^2e^{\lambda t}\] 
    Quindi si ha una soluzione particolare:
    \[\overline{y}(t) = Ct^2e^{\lambda t}\]
    con $C \in \mathbb{R}$. 
    Osserviamo che in questa classe particolare di termini noti del tipo $Ae^{\lambda t}$ con $\lambda \in \mathbb{C}$ rientrano anche in casi:
    \[\cos{\omega t},\sin{\omega t}, e^{\mu t}\cos{\omega t}, e^{\mu t}\sin{\omega t} \; \; \; \text{con $\omega \in \mathbb{R}$ }\]

\end{itemize}

\ex{}{
Si trovi una soluzione particolare dell'equazione differenziale:
\[y'' + 3y = t + 2\cos{t}\]
Per trovare una soluzione particolare dell'equazione non omogenea dobbiamo cercare una funzione $f(t)$ tale che:
\[f(t) = t + 2\cos{t}\]
Questo termine è la somma di due funzioni:
\begin{itemize}
    \item $t$, un polinomio di primo grado
    \item $2\cos{t}$, una funzione trigonometrica
\end{itemize}
Per questo motivo cerchiamo una soluzione particolare come la somma di due soluzioni, ciascuna
ciascuna associata a uno dei due termini:
\[y_p = y_{p1} + y_{p2}\]
Quindi andiamo per step e cerchiamo di trovare una soluzione per il termine $t$ e un'altra per il termine $2\cos{t}$.
\begin{itemize}
    \item Per il termine $t$ che è un polinomio di primo grado, si cerca una funzione del tipo:
    \[y_{A_1}(t) = C_1t + C_0\]
    dove $A, B$ sono coefficienti da determinare.
    Calcoliamo le derivate:
    \[y_{A1}'(t) = C_1\]
    \[y_{A1}''(t) = 0\]
    Ora sostituiamo le derivate nell'equazione differenziale:
    \begin{align*}
        y'' + 3y &= t\\
        0 + 3(C_1t + C_0) &= t\\
        3C_1 + 3C_0 &= t
    \end{align*}
    Quindi $C_1 = 1/3$ e $C_0 = 0$. Quindi la soluzione per il termine $t$ è:
    \[y_{p1}(t) = \frac{1}{3}t\]
    \item Procediamo ora per $2\cos{t}$ che è una funzione trigonometrica. Si cerca una soluzione del tipo:
    \[y_{A2}(t) = A\gamma(t)e^{\lambda t}\]
    dove $\gamma(t)$ è ancora sconosciuta, $\lambda = i$ e $A = 2$.
    Quindi:
    \[y_{A2}(t) = 2\gamma(t)e^{it}\]
    Troviamo $\gamma(t)$, dato $a = 0$ e $b = 3$, si ha:
    \begin{align*}
        \gamma'' + (2\lambda + a)\gamma' + (\lambda^2 + \lambda a + b)\gamma &= A\\
        \cancel{\gamma''} + \cancel{2i\gamma'} + 2\gamma &= 2\\
        2\gamma &= 2 \Longrightarrow \gamma = 1
    \end{align*}
    Quindi la soluzione per il termine $2\cos{t}$ è:
    \[y_{p2}(t) = 2e^{it}\]
    Di conseguenza sommando le due soluzioni particolari si ottiene la soluzione particolare dell'equazione non omogenea:
    \[y_p(t) = \frac{1}{3}t + 2e^{it}\]
\end{itemize}
}



\end{document}